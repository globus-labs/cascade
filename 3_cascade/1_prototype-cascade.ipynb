{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a850a23-dd4a-49d1-8d24-9fa0500f85af",
   "metadata": {},
   "source": [
    "# Cascade: serial prototype implementation\n",
    "\n",
    "Here we use some of the classes we've written to create a serial prototype run of cascade\n",
    "\n",
    "This is the minimum viable run, intended to inform upcoming design decisions before distributed runs.\n",
    "\n",
    "No science is done here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c49f1f6-3a41-4d70-8126-236faccc3f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/miniconda3/envs/cascade/lib/python3.11/site-packages/e3nn/o3/_wigner.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n",
      "/home/mike/miniconda3/envs/cascade/lib/python3.11/site-packages/torchani/aev.py:16: UserWarning: cuaev not installed\n",
      "  warnings.warn(\"cuaev not installed\")\n",
      "/home/mike/miniconda3/envs/cascade/lib/python3.11/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "import ase\n",
    "from ase.io import read, write\n",
    "from ase.io.trajectory import Trajectory, TrajectoryWriter\n",
    "from ase import units\n",
    "from ase.md import MDLogger, VelocityVerlet\n",
    "import numpy as np\n",
    "from mace.calculators import mace_mp\n",
    "\n",
    "\n",
    "from cascade.utils import canonicalize, apply_calculator\n",
    "from cascade.auditor import RandomAuditor\n",
    "from cascade.learning.torchani import TorchANI\n",
    "from cascade.learning.torchani.build import make_output_nets, make_aev_computer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a27e82-15de-4767-befb-72b46f7fb6ce",
   "metadata": {},
   "source": [
    "## Read in structure\n",
    "We'll do these simulations on a Si 2x2x2 with a vacancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59fc8963-e05d-449a-aeca-19d8aee6dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = read('../0_setup/initial-geometries/si-vacancy-2x2x2.vasp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc76b922-d1ef-4b0d-a9c2-4ef5aea84819",
   "metadata": {},
   "source": [
    "## Set up calculator\n",
    "\n",
    "We'll use a small MACE model as our *target*.   \n",
    "That is to say, MACE is our ground truth physics.   \n",
    "(We want fast for this prototype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a8ef58-4ee3-4686-9ff4-3942211e23c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Materials Project MACE for MACECalculator with /home/mike/.cache/mace/20231210mace128L0_energy_epoch249model\n",
      "Using float32 for MACECalculator, which is faster but less accurate. Recommended for MD. Use float64 for geometry optimization.\n",
      "Default dtype float32 does not match model dtype float64, converting models to float32.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/miniconda3/envs/cascade/lib/python3.11/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/mike/miniconda3/envs/cascade/lib/python3.11/site-packages/mace/calculators/mace.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(f=model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "calc = mace_mp('small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5584da-e85c-4558-8150-c8fee87848a0",
   "metadata": {},
   "source": [
    "## Set up learner\n",
    "\n",
    "We'll fit two ANI models to MACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8f2e17c-c414-42da-ba43-3ebe7a49176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = TorchANI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29fab573-4c07-49d0-aeed-db13b6c8f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = list(set(atoms.symbols))\n",
    "aev = make_aev_computer(species)\n",
    "\n",
    "model = aev, make_output_nets(species, aev), dict((s, 0.) for s in species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8623b624-6d03-42b6-bf76-2fd17043a8ac",
   "metadata": {},
   "source": [
    "## Class for trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62cbd7c-4a4e-46a9-8d70-b986a95ac792",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CascadeTrajectory:\n",
    "    \"\"\"A class to encasplulate a cascade trajectory\n",
    "\n",
    "    This is useful for reading and auditing trajectories\n",
    "    so we know where to start sampling from (e.g., after the last trusted timestep)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, \n",
    "                 path: str, \n",
    "                 starting: ase.Atoms = None):\n",
    "        self.path = path\n",
    "        self.starting = starting\n",
    "       \n",
    "        if self.starting is not None:\n",
    "                write(self.path, self.starting)\n",
    "        else:\n",
    "            self.starting = read(self.path)\n",
    "        \n",
    "        self.current = starting\n",
    "        self.current_timestep = 0\n",
    "        self.last_trusted_timestep = 0\n",
    "    \n",
    "    def read(self, index=':', *args, **kwargs) -> list[ase.Atoms]:\n",
    "        \"\"\"Read the trajectory into an iterable of atoms\"\"\"\n",
    "        return read(self.path, *args, index=index, **kwargs)\n",
    "\n",
    "    def get_untrusted_segment(self) -> list[ase.Atoms]:\n",
    "        \"\"\"Return the part of the trajectory that needs to be audited\"\"\"\n",
    "        return read(self.path, index=f'{self.last_trusted_timestep+1}:')\n",
    "    \n",
    "    def trim_untrusted_segment(self):\n",
    "        \"\"\"Remove the part of a trajectory that failed an audit, updating timesteps as appropriate\"\"\"\n",
    "        # todo: is there a way to do this without loading into memory?\n",
    "        write(self.path, read(self.path, index=f':{self.last_trusted_timestep+1}'))\n",
    "        self.current_timestep = self.last_trusted_timestep\n",
    "\n",
    "    def __repr__(self): \n",
    "        return f\"CascadeTrajectory(path={self.path}, current_timestep={self.current_timestep}, last_trusted_timestep={self.last_trusted_timestep})\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1f1599-f541-4d40-affb-8368b3292afb",
   "metadata": {},
   "source": [
    "### tests \n",
    "\n",
    "#### Todo: (these should go in a test suite if we're keeping this), update the coords or something to make sure the right things are getting deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b225651-b0ee-46be-ac8d-8b55d8ea4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "write('test.traj', [atoms, atoms.copy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "766de0f0-2df7-4dc2-813a-06e414047c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = CascadeTrajectory('test.traj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10c2c251-dcc8-4e1d-b8fc-f4e51fd9f552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Atoms(symbols='Si63', pbc=True, cell=[10.86, 10.86, 10.86]),\n",
       " Atoms(symbols='Si63', pbc=True, cell=[10.86, 10.86, 10.86])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0e8a83c-8c95-44f3-ab42-02806c1ed390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Atoms(symbols='Si63', pbc=True, cell=[10.86, 10.86, 10.86])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj.get_untrusted_segment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60a186dd-037b-4395-8284-5933d051c3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Atoms(symbols='Si63', pbc=True, cell=[10.86, 10.86, 10.86])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read('test.traj', index=':1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "004ff4db-6f18-43dc-a441-e09fb570f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj.trim_untrusted_segment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c17f0a18-f39d-4e52-8db3-dfe18b8f7423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Atoms(symbols='Si63', pbc=True, cell=[10.86, 10.86, 10.86])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj.read()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18029a5c-a96a-44ad-ab72-5668f20a57c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fffbbce3-a5d2-4f14-9095-261309a069a3",
   "metadata": {},
   "source": [
    "## Minimum viable cascasde loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "568bdb51-d2a5-4ff5-9b50-13d4bc111e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/miniconda3/envs/cascade/lib/python3.11/site-packages/torchani/utils.py:158: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self_energies = torch.tensor(self_energies, dtype=torch.double)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On traj 1/2\n",
      "Running ML-driven dynamics\n",
      "CascadeTrajectory(path=si-diffusion-seed=0.traj, current_timestep=64, last_trusted_timestep=0)\n",
      "On traj 2/2\n",
      "Running ML-driven dynamics\n",
      "CascadeTrajectory(path=si-diffusion-seed=1.traj, current_timestep=64, last_trusted_timestep=0)\n",
      "done 0 / 2\n",
      "On traj 1/2\n",
      "Auditing trajectory\n",
      "score < threshold (0.3745401188473625 < 0.5, marking recent segment as trusted\n",
      "CascadeTrajectory(path=si-diffusion-seed=0.traj, current_timestep=64, last_trusted_timestep=64)\n",
      "On traj 2/2\n",
      "Auditing trajectory\n",
      "score < threshold (0.034388521115218396 < 0.5, marking recent segment as trusted\n",
      "CascadeTrajectory(path=si-diffusion-seed=1.traj, current_timestep=64, last_trusted_timestep=64)\n",
      "done 0 / 2\n",
      "On traj 1/2\n",
      "Running ML-driven dynamics\n",
      "CascadeTrajectory(path=si-diffusion-seed=0.traj, current_timestep=128, last_trusted_timestep=64)\n",
      "On traj 2/2\n",
      "Running ML-driven dynamics\n",
      "CascadeTrajectory(path=si-diffusion-seed=1.traj, current_timestep=128, last_trusted_timestep=64)\n",
      "done 0 / 2\n",
      "On traj 1/2\n",
      "Auditing trajectory\n",
      "score > threshold (0.6688412526636073 > 0.5), running audit calculations and dropping untrusted segment\n",
      "CascadeTrajectory(path=si-diffusion-seed=0.traj, current_timestep=64, last_trusted_timestep=64)\n",
      "On traj 2/2\n",
      "Auditing trajectory\n",
      "score < threshold (0.33761517140362796 < 0.5, marking recent segment as trusted\n",
      "CascadeTrajectory(path=si-diffusion-seed=1.traj, current_timestep=128, last_trusted_timestep=128)\n",
      "done 0 / 2\n",
      "On traj 1/2\n",
      "Running ML-driven dynamics\n",
      "CascadeTrajectory(path=si-diffusion-seed=0.traj, current_timestep=128, last_trusted_timestep=64)\n",
      "On traj 2/2\n",
      "Traj is completed, continuing\n",
      "done 1 / 2\n",
      "On traj 1/2\n",
      "Auditing trajectory\n",
      "score > threshold (0.940523264489604 > 0.5), running audit calculations and dropping untrusted segment\n",
      "CascadeTrajectory(path=si-diffusion-seed=0.traj, current_timestep=64, last_trusted_timestep=64)\n",
      "On traj 2/2\n",
      "Traj is completed, continuing\n",
      "done 1 / 2\n",
      "On traj 1/2\n",
      "Running ML-driven dynamics\n",
      "CascadeTrajectory(path=si-diffusion-seed=0.traj, current_timestep=128, last_trusted_timestep=64)\n",
      "On traj 2/2\n",
      "Traj is completed, continuing\n",
      "done 1 / 2\n",
      "On traj 1/2\n",
      "Auditing trajectory\n",
      "score < threshold (0.09367476782809248 < 0.5, marking recent segment as trusted\n",
      "CascadeTrajectory(path=si-diffusion-seed=0.traj, current_timestep=128, last_trusted_timestep=128)\n",
      "On traj 2/2\n",
      "Traj is completed, continuing\n",
      "done 1 / 2\n",
      "On traj 1/2\n",
      "Traj is completed, continuing\n",
      "On traj 2/2\n",
      "Traj is completed, continuing\n",
      "done 2 / 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create two cascasde trajectories from the same starating point but with different seeds\n",
    "seeds = [0, 1]\n",
    "trajectories = [CascadeTrajectory(path=f'si-diffusion-seed={s}.traj', \n",
    "                                  starting=atoms.copy()) for s in seeds]\n",
    "# notably, right now, the seeds have no effect since our dynamics are NVE\n",
    "\n",
    "\n",
    "total_steps = 128    # how long will our final trajectories be\n",
    "increment_steps = 64 # how many steps to run with ML at a time\n",
    "\n",
    "# audits are random\n",
    "auditor = RandomAuditor(random_state=42)\n",
    "threshold = 0.5 # this is the 'score' threshold on the auditor\n",
    "\n",
    "done = False\n",
    "i = 0 # track while loop iterations\n",
    "max_iter = 10 # dont go above this\n",
    "while not done:\n",
    "    \n",
    "    done_ctr = 0 # count how many trajectories are done\n",
    "    \n",
    "    for j, traj in enumerate(trajectories):\n",
    "        \n",
    "        ## Check if this trajectory is done\n",
    "        print(f'On traj {j+1}/{len(trajectories)}')\n",
    "        if traj.last_trusted_timestep == total_steps: \n",
    "            done_ctr += 1\n",
    "            print('Traj is completed, continuing')\n",
    "            continue\n",
    "\n",
    "        \n",
    "        ## if we've advanced past a trusted segment, lets audit it\n",
    "        if traj.current_timestep > traj.last_trusted_timestep: \n",
    "            print('Auditing trajectory')\n",
    "            segment = traj.get_untrusted_segment()\n",
    "            score, audit_frames = auditor.audit(segment, n_audits=32)\n",
    "            if score > threshold: \n",
    "                print(f'score > threshold ({score} > {threshold}), running audit calculations and dropping untrusted segment')\n",
    "                segment = apply_calculator(calc, segment)\n",
    "                traj.trim_untrusted_segment()\n",
    "            else:\n",
    "                print(f'score < threshold ({score} < {threshold}, marking recent segment as trusted')\n",
    "                traj.last_trusted_timestep = traj.current_timestep\n",
    "\n",
    "        \n",
    "        # otherwise we can run the ML-driven dynamics \n",
    "        else:\n",
    "            # then we run dynamics\n",
    "            print('Running ML-driven dynamics')\n",
    "            traj.current.calc = learner.make_calculator(model, device='cpu')\n",
    "            dyn = VelocityVerlet(atoms=traj.current,\n",
    "                                 timestep=1*units.fs,\n",
    "                                 trajectory=TrajectoryWriter(traj.path, mode='a')\n",
    "                                )\n",
    "            dyn.run(increment_steps)\n",
    "            traj.current_timestep += increment_steps\n",
    "        print(traj)\n",
    "        \n",
    "    i += 1\n",
    "    print(f'done {done_ctr} / {len(trajectories)}')\n",
    "    done = done_ctr == len(trajectories) or i == max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea864495-142f-4640-b1c6-eaa341dbf581",
   "metadata": {},
   "source": [
    "## did those complete? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07448032-737c-49ac-9958-2829b95b841e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[129, 129]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(t.read()) for t in trajectories]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ebda21-bbbd-4e07-842b-d49e8f83ac7e",
   "metadata": {},
   "source": [
    "Seems done enough for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dfe13d-24ea-4c0a-b9e3-4fed5133b255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
