{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a2a468-d755-4ab7-aadc-d5aa2850f13b",
   "metadata": {},
   "source": [
    "# Compare Runs\n",
    "Compare different configurations for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e921a470-f9da-42b5-b1b7-ac91e98b0f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from ase import units\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9600085-64c6-4801-aada-e96ba27c6ae1",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c03b9-f11c-46b8-8ea5-ebf6317f4f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hash = '4380cfde'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd7313-fa04-4bc1-9209-f279fc2d65e6",
   "metadata": {},
   "source": [
    "## Pull Runs from MLFlow\n",
    "ML flow uses local storage in the `mlruns` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e546253-7512-40e7-9b1d-6f81f60320ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_run_summaries() -> list[dict]:\n",
    "    \"\"\"Get all runs for a certain experiment\n",
    "    \n",
    "    Pulls the metrics, parameters, tags, and the artifact URI (so we can download data later).\n",
    "    \n",
    "    Returns:z\n",
    "        List of dictionaries describing each run\n",
    "    \"\"\"\n",
    "    \n",
    "    output = []\n",
    "    for path in Path('runs').rglob('performance.json'):\n",
    "        path = path.parent\n",
    "\n",
    "        # Load the input parameters\n",
    "        date, run_hash = path.name.rsplit(\"-\", 1)\n",
    "        record = {\n",
    "            'path': path,\n",
    "            'hash': run_hash,\n",
    "            'date': datetime.fromisoformat(date)\n",
    "        }\n",
    "        with open(path / 'params.json') as fp:\n",
    "            for key, val in json.load(fp).items():\n",
    "                record[f'param.{key}'] = val\n",
    "\n",
    "        # Load in performance\n",
    "        with open(path / 'performance.json') as fp:\n",
    "            for key, val in json.load(fp).items():\n",
    "                record[f'metric.{key}'] = val\n",
    "        \n",
    "        output.append(record)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e79f27-feaa-41ab-99c1-3e5a8982acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(gather_run_summaries()).sort_values('date')\n",
    "summary.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019cdffc-a965-4ce3-8876-dc50f55ffe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['param.test_hash']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f0484-d581-42a1-a2c9-f8cce4cd6267",
   "metadata": {},
   "source": [
    "## Evaluate Best Model\n",
    "See how the model's error wrt frame appears and learning curve during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec03612-06e6-4178-ab0e-9b4ae4e0d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_runs = summary[summary['param.test_hash'] == data_hash]\n",
    "best_run = top_runs.sort_values('metric.force_mean_error', ascending=True).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1c100-9640-4cd3-92d1-e688a117c06f",
   "metadata": {},
   "source": [
    "Pull out the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6380bf3-34b3-463c-9a53-b5affac3eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict((k[6:], v) for k, v in best_run.to_dict().items() if k.startswith('param.'))\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f155b19a-7228-449c-ada7-eb3720dfc66f",
   "metadata": {},
   "source": [
    "Plot the error as a function of timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e57f2-a243-46df-97bd-e14ba6701139",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load(best_run['path'] / 'test_pred.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2dfe2c-4408-4ceb-84e4-9f3afb7d7575",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = np.load(best_run['path'] / 'test_true.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d2926-2523-4af8-91be-bac845ca0333",
   "metadata": {},
   "source": [
    "Predicted vs actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76877e7a-0380-431d-b15f-935fc494fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_e_pera = preds['energy'] / preds['count']\n",
    "true_e_pera = true['energy'] / true['count']\n",
    "for pera in [pred_e_pera, true_e_pera]:\n",
    "    pera -= true_e_pera.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7526179a-6e34-466c-a754-5ddd011a9b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(6.4, 2.3))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.scatter(pred_e_pera, true_e_pera, s=2)\n",
    "lim = [\n",
    "    min(pred_e_pera.min(), true_e_pera.min()),\n",
    "    max(pred_e_pera.max(), true_e_pera.max())\n",
    "]\n",
    "ax.set_xlim(lim)\n",
    "ax.set_ylim(lim)\n",
    "ax.plot(ax.get_xlim(), ax.get_xlim(), 'k--', lw=1)\n",
    "\n",
    "r2_score = np.corrcoef(pred_e_pera, true_e_pera)[0, 1]\n",
    "ax.text(0.1, 0.8, f'$R^2$: {r2_score: .2f}', transform=ax.transAxes, fontsize=10)\n",
    "\n",
    "ax.set_title('Energy (meV/atom)', loc='left', fontsize=10)\n",
    "\n",
    "ax = axs[1]\n",
    "ax.scatter(preds['forces'].flatten(), true['forces'].flatten(), s=2)\n",
    "ax.set_title('Forces (eV/$\\\\AA$)', loc='left', fontsize=10)\n",
    "\n",
    "ax.set_xlim(ax.get_ylim())\n",
    "ax.set_ylim(ax.get_ylim())\n",
    "ax.plot(ax.get_xlim(), ax.get_xlim(), 'k--', lw=1)\n",
    "\n",
    "rmse = np.sqrt(np.power(preds['forces'].flatten() - true['forces'].flatten(), 2).mean())\n",
    "ax.text(0.1, 0.9, f'RMSE: {rmse:.2f}', transform=ax.transAxes, fontsize=10)\n",
    "\n",
    "\n",
    "ax = axs[2]\n",
    "ax.scatter(preds['stress'] / units.GPa, true['stress'] / units.GPa, s=2)\n",
    "ax.set_title('Stress (GPa)', loc='left', fontsize=10)\n",
    "\n",
    "rmse = np.sqrt(np.power(preds['stress'] - true['stress'], 2).mean()) / units.GPa\n",
    "ax.text(0.1, 0.9, f'RMSE: {rmse:.2f}', transform=ax.transAxes, fontsize=10)\n",
    "\n",
    "ax.set_xlim(ax.get_ylim())\n",
    "ax.set_ylim(ax.get_ylim())\n",
    "ax.plot(ax.get_xlim(), ax.get_xlim(), 'k--', lw=1)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('ML')\n",
    "    ax.set_ylabel('DFT')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd593879-596d-4ca1-ba50-c5018a297869",
   "metadata": {},
   "source": [
    "Plot the training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31efba27-e8a4-4eb9-b11a-e4967e00707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = pd.read_csv(best_run['path'] / \"log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4c52b-0faa-4ab2-bf3e-f531a505ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(3.5, 2.))\n",
    "\n",
    "for a, c, color in zip(axs, ['s_rmse_valid', 'f_rmse_valid', 'e_rmse_valid'], ['red', 'blue', 'gray']):\n",
    "    a.plot(train_log[c], color=color)\n",
    "    a.set_ylabel(c.split(\"_\")[0])\n",
    "    a.set_label('Loss')\n",
    "\n",
    "axs[-1].set_xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a455a-1d2f-4226-b70d-630a941adae6",
   "metadata": {},
   "source": [
    "## Compare Pre-Trained and Random Start\n",
    "See the test performance for the same architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaac1c4-6a97-4b91-b017-cf94c5912ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.5, 2.))\n",
    "\n",
    "top_runs = top_runs.sort_values('param.num_epochs')\n",
    "ax.loglog(\n",
    "    top_runs['param.num_epochs'],\n",
    "    top_runs['metric.force_mean_error'],\n",
    "    '--o',\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Force RMSE (eV/$\\\\AA$)')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633074b-ba73-4ba0-937d-2348cbe25737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
